{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    train_dataset = h5py.File('../../Downloads/train_signs.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('../../Downloads/test_signs.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080, 64, 64, 3)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1080)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train_orig\n",
    "Y_train=Y_train_orig.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 64, 64, 3)\n",
      "(1080, 1)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)\n",
    "print (Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 1080)\n"
     ]
    }
   ],
   "source": [
    "Y_train=convert_to_one_hot(Y_train, 6)\n",
    "print (Y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 6)\n"
     ]
    }
   ],
   "source": [
    "Y_train=Y_train.T\n",
    "print (Y_train.shape)\n",
    "X_train = X_train_orig/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "x=tf.placeholder(tf.float32, shape=[None, 64,64,3])\n",
    "y=tf.placeholder(tf.float32, shape=[None, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1=tf.get_variable(\"W1\",shape=[4,4,3,8],dtype=tf.float32,initializer=tf.contrib.layers.xavier_initializer())\n",
    "W2=tf.get_variable(\"W2\",shape=[2,2,8,16],dtype=tf.float32,initializer=tf.contrib.layers.xavier_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1=tf.nn.conv2d(x,W1,strides=[1,1,1,1],padding='SAME')\n",
    "a1=tf.nn.relu(z1)\n",
    "p1=tf.nn.max_pool(a1,ksize=[1,8,8,1],strides=[1,8,8,1],padding='SAME')\n",
    "z2=tf.nn.conv2d(p1,W2,strides=[1,1,1,1],padding='SAME')\n",
    "a2=tf.nn.relu(z2)\n",
    "p2=tf.nn.max_pool(a2,ksize=[1,4,4,1],strides=[1,4,4,1],padding='SAME')\n",
    "\n",
    "p=tf.contrib.layers.flatten(p2)\n",
    "z3=tf.contrib.layers.fully_connected(p,6,activation_fn=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits( labels=y, logits=z3))\n",
    "optimizer=tf.train.AdamOptimizer(0.009).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 1.813791\n",
      "Cost after epoch 1: 1.793399\n",
      "Cost after epoch 2: 1.785255\n",
      "Cost after epoch 3: 1.779145\n",
      "Cost after epoch 4: 1.776160\n",
      "Cost after epoch 5: 1.773582\n",
      "Cost after epoch 6: 1.767942\n",
      "Cost after epoch 7: 1.761678\n",
      "Cost after epoch 8: 1.756579\n",
      "Cost after epoch 9: 1.748854\n",
      "Cost after epoch 10: 1.740276\n",
      "Cost after epoch 11: 1.728979\n",
      "Cost after epoch 12: 1.717050\n",
      "Cost after epoch 13: 1.704452\n",
      "Cost after epoch 14: 1.690390\n"
     ]
    }
   ],
   "source": [
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    cos=0\n",
    "    for epoch in range(15):\n",
    "        _,cost_=sess.run([optimizer,cost],feed_dict={x:X_train, y:Y_train})\n",
    "        cos=cost_\n",
    "        print (\"Cost after epoch %i: %f\" % (epoch, cos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 1.891707\n",
      "Cost after epoch 1: 1.799246\n",
      "Cost after epoch 2: 1.788396\n",
      "Cost after epoch 3: 1.790424\n",
      "Cost after epoch 4: 1.790019\n",
      "Cost after epoch 5: 1.788342\n",
      "Cost after epoch 6: 1.785468\n",
      "Cost after epoch 7: 1.782430\n",
      "Cost after epoch 8: 1.777115\n",
      "Cost after epoch 9: 1.772377\n",
      "Cost after epoch 10: 1.766533\n",
      "Cost after epoch 11: 1.762457\n",
      "Cost after epoch 12: 1.756638\n",
      "Cost after epoch 13: 1.751289\n",
      "Cost after epoch 14: 1.742537\n",
      "Cost after epoch 15: 1.735810\n",
      "Cost after epoch 16: 1.724804\n",
      "Cost after epoch 17: 1.714712\n",
      "Cost after epoch 18: 1.700798\n",
      "Cost after epoch 19: 1.686522\n",
      "Cost after epoch 20: 1.669314\n",
      "Cost after epoch 21: 1.652373\n",
      "Cost after epoch 22: 1.633935\n",
      "Cost after epoch 23: 1.612604\n",
      "Cost after epoch 24: 1.589270\n",
      "Cost after epoch 25: 1.564989\n",
      "Cost after epoch 26: 1.538908\n",
      "Cost after epoch 27: 1.517791\n",
      "Cost after epoch 28: 1.490051\n",
      "Cost after epoch 29: 1.463300\n",
      "Cost after epoch 30: 1.439816\n",
      "Cost after epoch 31: 1.411429\n",
      "Cost after epoch 32: 1.389488\n",
      "Cost after epoch 33: 1.364330\n",
      "Cost after epoch 34: 1.336339\n",
      "Cost after epoch 35: 1.319449\n",
      "Cost after epoch 36: 1.299823\n",
      "Cost after epoch 37: 1.276815\n",
      "Cost after epoch 38: 1.261068\n",
      "Cost after epoch 39: 1.239779\n",
      "Cost after epoch 40: 1.222337\n",
      "Cost after epoch 41: 1.209207\n",
      "Cost after epoch 42: 1.181468\n",
      "Cost after epoch 43: 1.174420\n",
      "Cost after epoch 44: 1.160959\n",
      "Cost after epoch 45: 1.145360\n",
      "Cost after epoch 46: 1.141244\n",
      "Cost after epoch 47: 1.115364\n",
      "Cost after epoch 48: 1.109462\n",
      "Cost after epoch 49: 1.101725\n",
      "Cost after epoch 50: 1.087776\n",
      "Cost after epoch 51: 1.072021\n",
      "Cost after epoch 52: 1.059490\n",
      "Cost after epoch 53: 1.043959\n",
      "Cost after epoch 54: 1.041433\n",
      "Cost after epoch 55: 1.025613\n",
      "Cost after epoch 56: 1.020446\n",
      "Cost after epoch 57: 1.005607\n",
      "Cost after epoch 58: 0.996804\n",
      "Cost after epoch 59: 0.993934\n",
      "Cost after epoch 60: 0.982353\n",
      "Cost after epoch 61: 0.979685\n",
      "Cost after epoch 62: 0.975299\n",
      "Cost after epoch 63: 0.974008\n",
      "Cost after epoch 64: 0.958121\n",
      "Cost after epoch 65: 0.945389\n",
      "Cost after epoch 66: 0.936119\n",
      "Cost after epoch 67: 0.931233\n",
      "Cost after epoch 68: 0.926777\n",
      "Cost after epoch 69: 0.915671\n",
      "Cost after epoch 70: 0.900767\n",
      "Cost after epoch 71: 0.893319\n",
      "Cost after epoch 72: 0.889647\n",
      "Cost after epoch 73: 0.881011\n",
      "Cost after epoch 74: 0.874378\n",
      "Cost after epoch 75: 0.862181\n",
      "Cost after epoch 76: 0.861255\n",
      "Cost after epoch 77: 0.850557\n",
      "Cost after epoch 78: 0.843774\n",
      "Cost after epoch 79: 0.833568\n",
      "Cost after epoch 80: 0.827435\n",
      "Cost after epoch 81: 0.822048\n",
      "Cost after epoch 82: 0.818010\n",
      "Cost after epoch 83: 0.813080\n",
      "Cost after epoch 84: 0.808946\n",
      "Cost after epoch 85: 0.807890\n",
      "Cost after epoch 86: 0.812394\n",
      "Cost after epoch 87: 0.809798\n",
      "Cost after epoch 88: 0.798862\n",
      "Cost after epoch 89: 0.788534\n",
      "Cost after epoch 90: 0.779384\n",
      "Cost after epoch 91: 0.776959\n",
      "Cost after epoch 92: 0.775156\n",
      "Cost after epoch 93: 0.758769\n",
      "Cost after epoch 94: 0.756896\n",
      "Cost after epoch 95: 0.760932\n",
      "Cost after epoch 96: 0.750321\n",
      "Cost after epoch 97: 0.746121\n",
      "Cost after epoch 98: 0.739134\n",
      "Cost after epoch 99: 0.735423\n",
      "Cost after epoch 100: 0.740722\n",
      "Cost after epoch 101: 0.721402\n",
      "Cost after epoch 102: 0.717355\n",
      "Cost after epoch 103: 0.724261\n",
      "Cost after epoch 104: 0.712920\n",
      "Cost after epoch 105: 0.704669\n",
      "Cost after epoch 106: 0.709404\n",
      "Cost after epoch 107: 0.700067\n",
      "Cost after epoch 108: 0.695692\n",
      "Cost after epoch 109: 0.690456\n",
      "Cost after epoch 110: 0.683244\n",
      "Cost after epoch 111: 0.682038\n",
      "Cost after epoch 112: 0.681861\n",
      "Cost after epoch 113: 0.678158\n",
      "Cost after epoch 114: 0.672291\n",
      "Cost after epoch 115: 0.677771\n",
      "Cost after epoch 116: 0.684655\n",
      "Cost after epoch 117: 0.683227\n",
      "Cost after epoch 118: 0.673138\n",
      "Cost after epoch 119: 0.656759\n",
      "Cost after epoch 120: 0.650429\n",
      "Cost after epoch 121: 0.657978\n",
      "Cost after epoch 122: 0.658015\n",
      "Cost after epoch 123: 0.644093\n",
      "Cost after epoch 124: 0.634817\n",
      "Cost after epoch 125: 0.640437\n",
      "Cost after epoch 126: 0.645102\n",
      "Cost after epoch 127: 0.635880\n",
      "Cost after epoch 128: 0.624729\n",
      "Cost after epoch 129: 0.622132\n",
      "Cost after epoch 130: 0.623645\n",
      "Cost after epoch 131: 0.620978\n",
      "Cost after epoch 132: 0.615483\n",
      "Cost after epoch 133: 0.610523\n",
      "Cost after epoch 134: 0.607316\n",
      "Cost after epoch 135: 0.606657\n",
      "Cost after epoch 136: 0.606763\n",
      "Cost after epoch 137: 0.606220\n",
      "Cost after epoch 138: 0.601967\n",
      "Cost after epoch 139: 0.600967\n",
      "Cost after epoch 140: 0.606667\n",
      "Cost after epoch 141: 0.616281\n",
      "Cost after epoch 142: 0.603129\n",
      "Cost after epoch 143: 0.587275\n",
      "Cost after epoch 144: 0.581161\n",
      "Cost after epoch 145: 0.583000\n",
      "Cost after epoch 146: 0.585938\n",
      "Cost after epoch 147: 0.582890\n",
      "Cost after epoch 148: 0.574654\n",
      "Cost after epoch 149: 0.567298\n",
      "Cost after epoch 150: 0.566242\n",
      "Cost after epoch 151: 0.568612\n",
      "Cost after epoch 152: 0.567002\n",
      "Cost after epoch 153: 0.558636\n",
      "Cost after epoch 154: 0.552007\n",
      "Cost after epoch 155: 0.552679\n",
      "Cost after epoch 156: 0.555191\n",
      "Cost after epoch 157: 0.553996\n",
      "Cost after epoch 158: 0.554481\n",
      "Cost after epoch 159: 0.559537\n",
      "Cost after epoch 160: 0.570091\n",
      "Cost after epoch 161: 0.577617\n",
      "Cost after epoch 162: 0.561157\n",
      "Cost after epoch 163: 0.535420\n",
      "Cost after epoch 164: 0.531746\n",
      "Cost after epoch 165: 0.546799\n",
      "Cost after epoch 166: 0.555657\n",
      "Cost after epoch 167: 0.530718\n",
      "Cost after epoch 168: 0.523208\n",
      "Cost after epoch 169: 0.533273\n",
      "Cost after epoch 170: 0.535095\n",
      "Cost after epoch 171: 0.517704\n",
      "Cost after epoch 172: 0.514198\n",
      "Cost after epoch 173: 0.521881\n",
      "Cost after epoch 174: 0.520209\n",
      "Cost after epoch 175: 0.508975\n",
      "Cost after epoch 176: 0.505486\n",
      "Cost after epoch 177: 0.506527\n",
      "Cost after epoch 178: 0.505580\n",
      "Cost after epoch 179: 0.499201\n",
      "Cost after epoch 180: 0.495676\n",
      "Cost after epoch 181: 0.494363\n",
      "Cost after epoch 182: 0.494593\n",
      "Cost after epoch 183: 0.490508\n",
      "Cost after epoch 184: 0.486679\n",
      "Cost after epoch 185: 0.484695\n",
      "Cost after epoch 186: 0.486382\n",
      "Cost after epoch 187: 0.485117\n",
      "Cost after epoch 188: 0.482484\n",
      "Cost after epoch 189: 0.482350\n",
      "Cost after epoch 190: 0.486685\n",
      "Cost after epoch 191: 0.497331\n",
      "Cost after epoch 192: 0.496745\n",
      "Cost after epoch 193: 0.498906\n",
      "Cost after epoch 194: 0.482494\n",
      "Cost after epoch 195: 0.464963\n",
      "Cost after epoch 196: 0.461051\n",
      "Cost after epoch 197: 0.469938\n",
      "Cost after epoch 198: 0.477594\n",
      "Cost after epoch 199: 0.467695\n",
      "Cost after epoch 200: 0.455869\n",
      "Cost after epoch 201: 0.450943\n",
      "Cost after epoch 202: 0.453039\n",
      "Cost after epoch 203: 0.455485\n",
      "Cost after epoch 204: 0.454272\n",
      "Cost after epoch 205: 0.450399\n",
      "Cost after epoch 206: 0.444043\n",
      "Cost after epoch 207: 0.439068\n",
      "Cost after epoch 208: 0.438405\n",
      "Cost after epoch 209: 0.439468\n",
      "Cost after epoch 210: 0.439116\n",
      "Cost after epoch 211: 0.437947\n",
      "Cost after epoch 212: 0.437542\n",
      "Cost after epoch 213: 0.435689\n",
      "Cost after epoch 214: 0.430868\n",
      "Cost after epoch 215: 0.426462\n",
      "Cost after epoch 216: 0.423532\n",
      "Cost after epoch 217: 0.421417\n",
      "Cost after epoch 218: 0.419560\n",
      "Cost after epoch 219: 0.418319\n",
      "Cost after epoch 220: 0.417697\n",
      "Cost after epoch 221: 0.417445\n",
      "Cost after epoch 222: 0.417275\n",
      "Cost after epoch 223: 0.418152\n",
      "Cost after epoch 224: 0.419804\n",
      "Cost after epoch 225: 0.422676\n",
      "Cost after epoch 226: 0.424164\n",
      "Cost after epoch 227: 0.426293\n",
      "Cost after epoch 228: 0.425714\n",
      "Cost after epoch 229: 0.421046\n",
      "Cost after epoch 230: 0.412358\n",
      "Cost after epoch 231: 0.402572\n",
      "Cost after epoch 232: 0.396460\n",
      "Cost after epoch 233: 0.395282\n",
      "Cost after epoch 234: 0.397582\n",
      "Cost after epoch 235: 0.400538\n",
      "Cost after epoch 236: 0.400770\n",
      "Cost after epoch 237: 0.398086\n",
      "Cost after epoch 238: 0.392331\n",
      "Cost after epoch 239: 0.386776\n",
      "Cost after epoch 240: 0.383373\n",
      "Cost after epoch 241: 0.382458\n",
      "Cost after epoch 242: 0.383167\n",
      "Cost after epoch 243: 0.384380\n",
      "Cost after epoch 244: 0.385101\n",
      "Cost after epoch 245: 0.384745\n",
      "Cost after epoch 246: 0.383349\n",
      "Cost after epoch 247: 0.380406\n",
      "Cost after epoch 248: 0.376703\n",
      "Cost after epoch 249: 0.372674\n",
      "Cost after epoch 250: 0.368972\n",
      "Cost after epoch 251: 0.366247\n",
      "Cost after epoch 252: 0.364429\n",
      "Cost after epoch 253: 0.363578\n",
      "Cost after epoch 254: 0.363313\n",
      "Cost after epoch 255: 0.363945\n",
      "Cost after epoch 256: 0.365667\n",
      "Cost after epoch 257: 0.370294\n",
      "Cost after epoch 258: 0.376979\n",
      "Cost after epoch 259: 0.387524\n",
      "Cost after epoch 260: 0.395959\n",
      "Cost after epoch 261: 0.395013\n",
      "Cost after epoch 262: 0.384066\n",
      "Cost after epoch 263: 0.362645\n",
      "Cost after epoch 264: 0.348687\n",
      "Cost after epoch 265: 0.348407\n",
      "Cost after epoch 266: 0.356704\n",
      "Cost after epoch 267: 0.363778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 268: 0.360328\n",
      "Cost after epoch 269: 0.350077\n",
      "Cost after epoch 270: 0.341422\n",
      "Cost after epoch 271: 0.339527\n",
      "Cost after epoch 272: 0.343347\n",
      "Cost after epoch 273: 0.346453\n",
      "Cost after epoch 274: 0.345971\n",
      "Cost after epoch 275: 0.341548\n",
      "Cost after epoch 276: 0.336006\n",
      "Cost after epoch 277: 0.332547\n",
      "Cost after epoch 278: 0.331476\n",
      "Cost after epoch 279: 0.332218\n",
      "Cost after epoch 280: 0.331943\n",
      "Cost after epoch 281: 0.331129\n",
      "Cost after epoch 282: 0.329578\n",
      "Cost after epoch 283: 0.326795\n",
      "Cost after epoch 284: 0.324303\n",
      "Cost after epoch 285: 0.321876\n",
      "Cost after epoch 286: 0.320254\n",
      "Cost after epoch 287: 0.319937\n",
      "Cost after epoch 288: 0.319820\n",
      "Cost after epoch 289: 0.319318\n",
      "Cost after epoch 290: 0.317973\n",
      "Cost after epoch 291: 0.316129\n",
      "Cost after epoch 292: 0.314318\n",
      "Cost after epoch 293: 0.312569\n",
      "Cost after epoch 294: 0.310798\n",
      "Cost after epoch 295: 0.309342\n",
      "Cost after epoch 296: 0.307993\n",
      "Cost after epoch 297: 0.306928\n",
      "Cost after epoch 298: 0.305980\n",
      "Cost after epoch 299: 0.304950\n",
      "0.8981481\n"
     ]
    }
   ],
   "source": [
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    cos=0\n",
    "    for epoch in range(300):\n",
    "        _,cost_=sess.run([optimizer,cost],feed_dict={x:X_train, y:Y_train})\n",
    "        cos=cost_\n",
    "        print (\"Cost after epoch %i: %f\" % (epoch, cos))\n",
    "        \n",
    "    predict_op=tf.argmax(z3,1)\n",
    "    #print(predict_op.shape)\n",
    "    #print (tf.argmax(y, 1).shape)\n",
    "    correct_prediction = tf.equal(predict_op, tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    train_accuracy = accuracy.eval({x: X_train, y: Y_train})\n",
    "    #test_accuracy = accuracy.eval({x: X_test, y: Y_test})\n",
    "    print(train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8981481\n"
     ]
    }
   ],
   "source": [
    "print (train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1=tf.nn.conv2d(x,W1,strides=[1,1,1,1],padding='VALID')\n",
    "a1=tf.nn.relu(z1)\n",
    "p1=tf.nn.max_pool(a1,ksize=[1,8,8,1],strides=[1,8,8,1],padding='VALID')\n",
    "z2=tf.nn.conv2d(p1,W2,strides=[1,1,1,1],padding='VALID')\n",
    "a2=tf.nn.relu(z2)\n",
    "p2=tf.nn.max_pool(a2,ksize=[1,4,4,1],strides=[1,4,4,1],padding='VALID')\n",
    "\n",
    "p=tf.contrib.layers.flatten(p2)\n",
    "z3=tf.contrib.layers.fully_connected(p,6,activation_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits( labels=y, logits=z3))\n",
    "optimizer=tf.train.AdamOptimizer(0.009).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 1.843714\n",
      "Cost after epoch 1: 1.803115\n",
      "Cost after epoch 2: 1.797971\n",
      "Cost after epoch 3: 1.792009\n",
      "Cost after epoch 4: 1.792710\n",
      "Cost after epoch 5: 1.790609\n",
      "Cost after epoch 6: 1.787047\n",
      "Cost after epoch 7: 1.789328\n",
      "Cost after epoch 8: 1.788612\n",
      "Cost after epoch 9: 1.785432\n",
      "Cost after epoch 10: 1.785769\n",
      "Cost after epoch 11: 1.785109\n",
      "Cost after epoch 12: 1.783922\n",
      "Cost after epoch 13: 1.782001\n",
      "Cost after epoch 14: 1.779765\n",
      "0.28055555\n"
     ]
    }
   ],
   "source": [
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    cos=0\n",
    "    for epoch in range(15):\n",
    "        _,cost_=sess.run([optimizer,cost],feed_dict={x:X_train, y:Y_train})\n",
    "        cos=cost_\n",
    "        print (\"Cost after epoch %i: %f\" % (epoch, cos))\n",
    "    predict_op=tf.argmax(z3,1)\n",
    "    #print(predict_op.shape)\n",
    "    #print (tf.argmax(y, 1).shape)\n",
    "    correct_prediction = tf.equal(predict_op, tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    train_accuracy = accuracy.eval({x: X_train, y: Y_train})\n",
    "    #test_accuracy = accuracy.eval({x: X_test, y: Y_test})\n",
    "    print(train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 1.798674\n",
      "Cost after epoch 1: 1.813242\n",
      "Cost after epoch 2: 1.788593\n",
      "Cost after epoch 3: 1.786873\n",
      "Cost after epoch 4: 1.787608\n",
      "Cost after epoch 5: 1.789833\n",
      "Cost after epoch 6: 1.787351\n",
      "Cost after epoch 7: 1.782971\n",
      "Cost after epoch 8: 1.780074\n",
      "Cost after epoch 9: 1.777187\n",
      "Cost after epoch 10: 1.774859\n",
      "Cost after epoch 11: 1.772079\n",
      "Cost after epoch 12: 1.767969\n",
      "Cost after epoch 13: 1.764758\n",
      "Cost after epoch 14: 1.763294\n",
      "Cost after epoch 15: 1.758247\n",
      "Cost after epoch 16: 1.749138\n",
      "Cost after epoch 17: 1.744081\n",
      "Cost after epoch 18: 1.740503\n",
      "Cost after epoch 19: 1.730628\n",
      "Cost after epoch 20: 1.721538\n",
      "Cost after epoch 21: 1.715736\n",
      "Cost after epoch 22: 1.704314\n",
      "Cost after epoch 23: 1.691881\n",
      "Cost after epoch 24: 1.682777\n",
      "Cost after epoch 25: 1.668061\n",
      "Cost after epoch 26: 1.654411\n",
      "Cost after epoch 27: 1.640585\n",
      "Cost after epoch 28: 1.622708\n",
      "Cost after epoch 29: 1.608129\n",
      "0.43703705\n"
     ]
    }
   ],
   "source": [
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    cos=0\n",
    "    for epoch in range(30):\n",
    "        _,cost_=sess.run([optimizer,cost],feed_dict={x:X_train, y:Y_train})\n",
    "        cos=cost_\n",
    "        print (\"Cost after epoch %i: %f\" % (epoch, cos))\n",
    "    predict_op=tf.argmax(z3,1)\n",
    "    #print(predict_op.shape)\n",
    "    #print (tf.argmax(y, 1).shape)\n",
    "    correct_prediction = tf.equal(predict_op, tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    train_accuracy = accuracy.eval({x: X_train, y: Y_train})\n",
    "    #test_accuracy = accuracy.eval({x: X_test, y: Y_test})\n",
    "    print(train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 1.806876\n",
      "Cost after epoch 1: 1.840260\n",
      "Cost after epoch 2: 1.801538\n",
      "Cost after epoch 3: 1.789351\n",
      "Cost after epoch 4: 1.791415\n",
      "Cost after epoch 5: 1.790464\n",
      "Cost after epoch 6: 1.790143\n",
      "Cost after epoch 7: 1.790160\n",
      "Cost after epoch 8: 1.789428\n",
      "Cost after epoch 9: 1.787779\n",
      "Cost after epoch 10: 1.785928\n",
      "Cost after epoch 11: 1.785399\n",
      "Cost after epoch 12: 1.784654\n",
      "Cost after epoch 13: 1.783269\n",
      "Cost after epoch 14: 1.781588\n",
      "Cost after epoch 15: 1.780046\n",
      "Cost after epoch 16: 1.778568\n",
      "Cost after epoch 17: 1.776016\n",
      "Cost after epoch 18: 1.774358\n",
      "Cost after epoch 19: 1.773032\n",
      "Cost after epoch 20: 1.770297\n",
      "Cost after epoch 21: 1.766062\n",
      "Cost after epoch 22: 1.762790\n",
      "Cost after epoch 23: 1.760878\n",
      "Cost after epoch 24: 1.755832\n",
      "Cost after epoch 25: 1.750611\n",
      "Cost after epoch 26: 1.745499\n",
      "Cost after epoch 27: 1.741089\n",
      "Cost after epoch 28: 1.734257\n",
      "Cost after epoch 29: 1.726961\n",
      "Cost after epoch 30: 1.719583\n",
      "Cost after epoch 31: 1.713959\n",
      "Cost after epoch 32: 1.704611\n",
      "Cost after epoch 33: 1.693319\n",
      "Cost after epoch 34: 1.684553\n",
      "Cost after epoch 35: 1.675269\n",
      "Cost after epoch 36: 1.666452\n",
      "Cost after epoch 37: 1.655608\n",
      "Cost after epoch 38: 1.642511\n",
      "Cost after epoch 39: 1.632733\n",
      "Cost after epoch 40: 1.629800\n",
      "Cost after epoch 41: 1.607296\n",
      "Cost after epoch 42: 1.598704\n",
      "Cost after epoch 43: 1.590974\n",
      "Cost after epoch 44: 1.572293\n",
      "Cost after epoch 45: 1.565539\n",
      "Cost after epoch 46: 1.553968\n",
      "Cost after epoch 47: 1.535854\n",
      "Cost after epoch 48: 1.531216\n",
      "Cost after epoch 49: 1.525018\n",
      "Cost after epoch 50: 1.502766\n",
      "Cost after epoch 51: 1.498443\n",
      "Cost after epoch 52: 1.484945\n",
      "Cost after epoch 53: 1.469861\n",
      "Cost after epoch 54: 1.474442\n",
      "Cost after epoch 55: 1.465659\n",
      "Cost after epoch 56: 1.442225\n",
      "Cost after epoch 57: 1.444779\n",
      "Cost after epoch 58: 1.424571\n",
      "Cost after epoch 59: 1.424228\n",
      "Cost after epoch 60: 1.407031\n",
      "Cost after epoch 61: 1.403937\n",
      "Cost after epoch 62: 1.407030\n",
      "Cost after epoch 63: 1.379997\n",
      "Cost after epoch 64: 1.385894\n",
      "Cost after epoch 65: 1.365678\n",
      "Cost after epoch 66: 1.368696\n",
      "Cost after epoch 67: 1.349702\n",
      "Cost after epoch 68: 1.355245\n",
      "Cost after epoch 69: 1.346614\n",
      "Cost after epoch 70: 1.332028\n",
      "Cost after epoch 71: 1.333367\n",
      "Cost after epoch 72: 1.320674\n",
      "Cost after epoch 73: 1.316444\n",
      "Cost after epoch 74: 1.303547\n",
      "Cost after epoch 75: 1.302171\n",
      "Cost after epoch 76: 1.288020\n",
      "Cost after epoch 77: 1.286944\n",
      "Cost after epoch 78: 1.273515\n",
      "Cost after epoch 79: 1.274546\n",
      "Cost after epoch 80: 1.264611\n",
      "Cost after epoch 81: 1.257238\n",
      "Cost after epoch 82: 1.255490\n",
      "Cost after epoch 83: 1.242142\n",
      "Cost after epoch 84: 1.239194\n",
      "Cost after epoch 85: 1.232386\n",
      "Cost after epoch 86: 1.222447\n",
      "Cost after epoch 87: 1.219400\n",
      "Cost after epoch 88: 1.210237\n",
      "Cost after epoch 89: 1.204335\n",
      "Cost after epoch 90: 1.199425\n",
      "Cost after epoch 91: 1.190503\n",
      "Cost after epoch 92: 1.187045\n",
      "Cost after epoch 93: 1.181345\n",
      "Cost after epoch 94: 1.171663\n",
      "Cost after epoch 95: 1.168466\n",
      "Cost after epoch 96: 1.162060\n",
      "Cost after epoch 97: 1.153360\n",
      "Cost after epoch 98: 1.149705\n",
      "Cost after epoch 99: 1.144306\n",
      "0.56666666\n"
     ]
    }
   ],
   "source": [
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    cos=0\n",
    "    for epoch in range(100):\n",
    "        _,cost_=sess.run([optimizer,cost],feed_dict={x:X_train, y:Y_train})\n",
    "        cos=cost_\n",
    "        print (\"Cost after epoch %i: %f\" % (epoch, cos))\n",
    "    predict_op=tf.argmax(z3,1)\n",
    "    #print(predict_op.shape)\n",
    "    #print (tf.argmax(y, 1).shape)\n",
    "    correct_prediction = tf.equal(predict_op, tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    train_accuracy = accuracy.eval({x: X_train, y: Y_train})\n",
    "    #test_accuracy = accuracy.eval({x: X_test, y: Y_test})\n",
    "    print(train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
